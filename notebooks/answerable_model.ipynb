{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV, cross_val_predict\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, make_scorer, roc_auc_score, confusion_matrix\n",
    "from model_training import WordCountTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerable_data = utils.load_data('../data/aqfiltered.json', 'answerable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerable_preprocessor(sentence):\n",
    "    sentence = utils.check_quotations(sentence)\n",
    "    sentence = word_tokenize(sentence)\n",
    "    \n",
    "    for i in range(len(sentence)):\n",
    "        sentence[i] = utils.check_camel_snakecase(sentence[i])\n",
    "        sentence[i] = sentence[i].lower()\n",
    "        \n",
    "        if sentence[i] in stop_words and sentence[i] not in ['who', 'what', 'when', 'where', 'why', 'how']:\n",
    "            sentence[i] = \"\"\n",
    "        elif sentence[i].isnumeric():\n",
    "            sentence[i] = \"numericnumber\"\n",
    "        elif utils.is_spelled_out_number(sentence[i]):\n",
    "            sentence[i] = \"nonnumericnumber\"\n",
    "        elif utils.is_TA_or_instructor_name(sentence[i]):\n",
    "            sentence[i] = \"name\"\n",
    "        elif utils.is_error_code(sentence[i]):\n",
    "            sentence[i] = \"errorcode\"\n",
    "        elif utils.is_system_word(sentence[i]):\n",
    "            sentence[i] = \"sys\"\n",
    "        elif utils.is_function(sentence[i]):\n",
    "            sentence[i] = \"func\"\n",
    "\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('ngram', TfidfVectorizer(preprocessor=None)),\n",
    "    ])),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7986742424242423\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(np.mean(cross_val_score(pipeline, data[:,0], data[:,1], n_jobs=-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[answerable_data[:,0][i], answerable_data[:,1][i]] for i in range(len(answerable_data)) if answerable_data[:,1][i] == 't' or answerable_data[:,1][i] == 'f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('ngram',\n",
       "                                                 TfidfVectorizer(analyzer='word',\n",
       "                                                                 binary=False,\n",
       "                                                                 decode_error='strict',\n",
       "                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                 encoding='utf-8',\n",
       "                                                                 input='content',\n",
       "                                                                 lowercase=True,\n",
       "                                                                 max_df=1.0,\n",
       "                                                                 max_features=None,\n",
       "                                                                 min_df=1,\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              1),\n",
       "                                                                 norm='l2',\n",
       "                                                                 preprocessor=None,\n",
       "                                                                 smooth_idf=True,\n",
       "                                                                 stop_words=None,\n",
       "                                                                 strip_accents=None,\n",
       "                                                                 sublinear_tf=False,\n",
       "                                                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                                 tokenizer=None,\n",
       "                                                                 use_idf=True,\n",
       "                                                                 vocabulary=None))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(data[:,0], data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('features',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('ngram',\n",
       "                                                                        TfidfVectorizer(analyzer='word',\n",
       "                                                                                        binary=False,\n",
       "                                                                                        decode_error='strict',\n",
       "                                                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                                                        encoding='utf-8',\n",
       "                                                                                        input='content',\n",
       "                                                                                        lowercase=True,\n",
       "                                                                                        max_df=1.0,\n",
       "                                                                                        max_features=None,\n",
       "                                                                                        min_df=1,\n",
       "                                                                                        ngram_range=(1,\n",
       "                                                                                                     1),\n",
       "                                                                                        norm='l2',\n",
       "                                                                                        p...\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__alpha': [1, 0.1, 0.01, 0.001],\n",
       "                         'features__ngram__max_features': [None, 100, 250, 500,\n",
       "                                                           1000, 1500, 2000,\n",
       "                                                           2500, 3000],\n",
       "                         'features__ngram__ngram_range': [(1, 1), (1, 2),\n",
       "                                                          (1, 3)],\n",
       "                         'features__ngram__norm': ('l1', 'l2'),\n",
       "                         'features__ngram__use_idf': (True, False)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'features__ngram__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'features__ngram__max_features': [None, 100, 250, 500, 1000, 1500, 2000, 2500, 3000],\n",
    "    'features__ngram__use_idf': (True, False),\n",
    "    'features__ngram__norm': ('l1', 'l2'),\n",
    "#     'clf__n_estimators': [100, 250, 500, 750, 1000],\n",
    "#     'clf__max_features': ['auto', 'log2'],\n",
    "#     'clf__max_depth': [None, 100, 500, 1000],\n",
    "#     'clf__min_samples_split': [2, 5, 10, 12],\n",
    "#     'clf__min_samples_leaf': [1, 2, 4, 8],\n",
    "#     'clf__criterion': ['gini', 'entropy'],\n",
    "#     'clf__bootstrap': [True, False],\n",
    "#     'clf__C': [.01, .1, 1, 10, 100],\n",
    "#     'clf__class_weight': [None, 'balanced']\n",
    "    'clf__alpha': [1, .1, .01, .001]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid, n_jobs=-1)\n",
    "search.fit(data[:,0], data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.807549</td>\n",
       "      <td>0.857353</td>\n",
       "      <td>0.830089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.790441</td>\n",
       "      <td>0.816075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision    Recall  F1 Score\n",
       "t   0.807549  0.857353  0.830089\n",
       "f   0.848333  0.790441  0.816075"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_precision = np.mean(cross_val_score(search.best_estimator_, data[:,0], data[:,1], cv=5, scoring=make_scorer(precision_score, pos_label='t'), n_jobs=-1))\n",
    "t_recall = np.mean(cross_val_score(search.best_estimator_, data[:,0], data[:,1], cv=5, scoring=make_scorer(recall_score, pos_label='t'), n_jobs=-1))\n",
    "t_f1 = np.mean(cross_val_score(search.best_estimator_, data[:,0], data[:,1], cv=5, scoring=make_scorer(f1_score, pos_label='t'), n_jobs=-1))\n",
    "                \n",
    "f_precision = np.mean(cross_val_score(search.best_estimator_, data[:,0], data[:,1], cv=5, scoring=make_scorer(precision_score, pos_label='f'), n_jobs=-1))\n",
    "f_recall = np.mean(cross_val_score(search.best_estimator_, data[:,0], data[:,1], cv=5, scoring=make_scorer(recall_score, pos_label='f'), n_jobs=-1))\n",
    "f_f1 = np.mean(cross_val_score(search.best_estimator_, data[:,0], data[:,1], cv=5, scoring=make_scorer(f1_score, pos_label='f'), n_jobs=-1))\n",
    "\n",
    "t = [t_precision, t_recall, t_f1]\n",
    "f = [f_precision, f_recall, f_f1]\n",
    "pd.DataFrame((t, f), index=['t', 'f'], columns=['Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8234848484848485\n",
      "Area Under Curve ROC: 0.8824908088235294\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(np.mean(cross_val_score(search.best_estimator_, data[:,0], data[:,1], n_jobs=-1))))\n",
    "print('Area Under Curve ROC: {}'.format(np.mean(cross_val_score(search.best_estimator_, data[:,0], data[:,1], cv=5, scoring='roc_auc', n_jobs=-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2416ff90>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = cross_val_predict(search.best_estimator_, data[:,0], data[:,1], cv=5)\n",
    "conf_mat = confusion_matrix(data[:,1], y_pred, labels=['t', 'f'])\n",
    "df_cm = pd.DataFrame(conf_mat, index = [i for i in ['t', 'f']],\n",
    "                  columns = [i for i in ['t', 'f']])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next().length() isn't working as expected\n",
      "t\n",
      "\n",
      "I'm having trouble installing packages necessary for SDL\n",
      "f\n",
      "\n",
      "constructor of Arraydeque and linkedDeque\n",
      "t\n",
      "\n",
      "How do I do things\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regarding stack\n",
      "t\n",
      "\n",
      "I would like to hack countable thoughts. \n",
      "t\n",
      "\n",
      "cant find SDL2/SDL2_gfxPrimitives.h \"Clang not found\"\n",
      "f\n",
      "\n",
      "I am getting an UnsupportedOperationException error. \n",
      "t\n",
      "\n",
      "I created some tests in my Main for addFront/addBack and they work as expected when I add a small number of elements, but they are not passing the LinkedDeque tests.\n",
      "\n",
      "My removeBack is not working and not sure why, currently debugging. \n",
      "f\n",
      "\n",
      "Something is weird with timeouts and we're not sure why\n",
      "t\n",
      "\n",
      "I don't know how to initialize arrays in java.\n",
      "f\n",
      "\n",
      "More error messages from mystring.c\n",
      "t\n",
      "\n",
      "add front is being weird and im not sure why.\n",
      "t\n",
      "\n",
      "Remove doesn't work and we can't figure out why.\n",
      "t\n",
      "\n",
      "intellij hangs indefinitely when running tests instead of failing normally\n",
      "f\n",
      "\n",
      "how to make a linked deque\n",
      "t\n",
      "\n",
      "Having trouble with assigning values to rdi\n",
      "f\n",
      "\n",
      "shouldn't be returning null\n",
      "\n",
      "t\n",
      "\n",
      "something is rotten in the B test (timeout errors)\n",
      "t\n",
      "\n",
      "I don't understand why sometimes my code thinks it is a better option to add a letter. \n",
      "t\n",
      "\n",
      "Don't think my array storing my values is getting properly initialized, all values always null\n",
      "\n",
      "f\n",
      "\n",
      "Git commands to move files from project 1 to project 2?\n",
      "f\n",
      "\n",
      "Need help explaining plateaus in iter for linked list\n",
      "f\n",
      "\n",
      "I keep timing out. Especially when I pass it to Git. I don't know how to make my code more efficient\n",
      "t\n",
      "\n",
      "I don't exactly know how to set up the constructor for the guitar string\n",
      "t\n",
      "\n",
      "I need a lot of help.  Also I waited for an hour to get down to nobody left in the queue just to see it at 0 people for 15 minutes.  Nobody contacted me, the page refreshed, and now there are 5 people in front of me.  I really need help on this and \n",
      "\n",
      "t\n",
      "\n",
      "test8 still giving memory error\n",
      "t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != data[:,1][i]:\n",
    "        print(data[:,0][i])\n",
    "        print(y_pred[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove doesn't work and we can't figure out why.\n",
      "['t']\n",
      "\n",
      "shouldn't be returning null\n",
      "\n",
      "['t']\n",
      "\n",
      "I keep timing out. Especially when I pass it to Git. I don't know how to make my code more efficient\n",
      "['t']\n",
      "\n",
      "Don't think my array storing my values is getting properly initialized, all values always null\n",
      "\n",
      "['f']\n",
      "\n",
      "I created some tests in my Main for addFront/addBack and they work as expected when I add a small number of elements, but they are not passing the LinkedDeque tests.\n",
      "\n",
      "My removeBack is not working and not sure why, currently debugging. \n",
      "['f']\n",
      "\n",
      "How do I do things\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regarding stack\n",
      "['t']\n",
      "\n",
      "I don't exactly know how to set up the constructor for the guitar string\n",
      "['t']\n",
      "\n",
      "Need help explaining plateaus in iter for linked list\n",
      "['f']\n",
      "\n",
      "I need a lot of help.  Also I waited for an hour to get down to nobody left in the queue just to see it at 0 people for 15 minutes.  Nobody contacted me, the page refreshed, and now there are 5 people in front of me.  I really need help on this and \n",
      "\n",
      "['t']\n",
      "\n",
      "how to make a linked deque\n",
      "['t']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data[:,1])):\n",
    "    if search.best_estimator_.predict(data[:,0])[i] != data[:,1][i]:\n",
    "        print(data[:,0][i])\n",
    "        print(search.best_estimator_.predict([data[:,0][i]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f'], dtype='<U332')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_.predict([\"I keep timing out. Especially when I pass it to Git. I don't know how to make my code more efficient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('ngram',\n",
       "                                                 TfidfVectorizer(analyzer='word',\n",
       "                                                                 binary=False,\n",
       "                                                                 decode_error='strict',\n",
       "                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                 encoding='utf-8',\n",
       "                                                                 input='content',\n",
       "                                                                 lowercase=True,\n",
       "                                                                 max_df=1.0,\n",
       "                                                                 max_features=500,\n",
       "                                                                 min_df=1,\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              3),\n",
       "                                                                 norm='l2',\n",
       "                                                                 preprocessor=<function answerable_preprocessor at 0x...\n",
       "                                                                 tokenizer=None,\n",
       "                                                                 use_idf=True,\n",
       "                                                                 vocabulary=None))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
